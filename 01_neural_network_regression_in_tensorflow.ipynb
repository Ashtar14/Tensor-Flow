{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with neural netrowks in Tensor FLow\n",
        "\n",
        "There are many definitions for a regression problem but in our case we are going to keep it simple : Predicting a numerical variable based on other variables even shorter prediting a number.\n"
      ],
      "metadata": {
        "id": "g7YuvLNjS9f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU2GpAEQT5DU",
        "outputId": "a19bb4e6-8e52-4629-b98e-84efd9f2102d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating some data to view and fit\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "# Creating features\n",
        "x = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
        "\n",
        "# Create Labels\n",
        "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
        "\n",
        "# Visualise it\n",
        "plt.scatter(x,y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "qvzgqKEIUDuY",
        "outputId": "b858c48b-64c6-44b3-bdd5-0b4a40dfc347"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y==x+10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9eeMv74U7ye",
        "outputId": "24f54047-3da8-4cda-8e8b-4b600602f8a5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the relation between our inputs and outputs\n"
      ],
      "metadata": {
        "id": "08JYAFtYVKhd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets Check out our input and output shape"
      ],
      "metadata": {
        "id": "uX_tlheMVc91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\",\"bathroom\",\"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info,house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Zp-4FfVesk",
        "outputId": "e7ed5ba3-3b7c-4ca3-eb27-2679c20837c7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x.shape\n",
        "output_shape  = y.shape\n",
        "input_shape,output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmeRWUn0WDwL",
        "outputId": "fcf8d044-2bba-4364-a156-5394759c9906"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our numpy arrays into tensors\n",
        "x = tf.constant(x)\n",
        "y = tf.constant(y)\n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcqHXd6_WYoC",
        "outputId": "72e19e01-bfee-4d15-e5d3-66c1a05f94ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape,output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgX9n-9mXl9Q",
        "outputId": "35a75786-8781-4f34-e3b3-6ae0bd96be4f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step in modeling with tensor flow\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function - the function that tells our function how wrong it is and optimizer that tells our function how to improve itself and evaluation metrics that tells how well is the performance of our model\n",
        "3. **Fitting a model** - letting the model try to find patterns betwqeen x and y"
      ],
      "metadata": {
        "id": "vtv6FTedXuJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Randdom Seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(loss=tf.keras.losses.mae,# mean absolute error\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "# Fit the model\n",
        "model.fit(tf.expand_dims(x,axis=-1),y,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL5UB_s7Y7lM",
        "outputId": "b516f828-2902-447e-8613-d18df5f4c5f4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabf51cad10>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out x and y\n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKH-Bj2wdGYx",
        "outputId": "79d487a0-6f62-486b-d36c-de845853c110"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make prediction using our model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred +11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDTbPz0eeKSh",
        "outputId": "67707322-4edf-4d30-d8c3-e4c2b4d7234e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fabf77808c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 52ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving Our Model\n",
        "\n",
        "We can improve our model by altering steps to crete the model\n",
        "\n",
        "1. **Creating the model** - we might add more layers, increase the number of hidden units (all called neurons) wihtin each of the hidden layers, change the activation function of each layer.\n",
        "\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the ** Learning rate** oof the optimization function.\n",
        "\n",
        "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (given more eaxamples to learn on)"
      ],
      "metadata": {
        "id": "DnZ0tG1XeTLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets re build our model \n",
        "\n",
        "#1. to Create the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2 Compile the mdoel\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "# 3. Fit the model (this time we will train for longer)\n",
        "model.fit(tf.expand_dims(x,axis=1),y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYm2suUrjLip",
        "outputId": "97770716-e601-4212-cfca-01687b4bb37c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabf8692fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind our selfs of data \n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LHkJkUMzQiF",
        "outputId": "89b793bf-fff8-4f10-e888-b980a18ae601"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see if our models presdiction has improved\n",
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvVRUkeF0_pJ",
        "outputId": "bfd230a0-dbaf-426d-982e-28fff6bd1350"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fabf53064d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 156ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model again with another change\n",
        "model = tf.keras.Sequential(\n",
        "    tf.keras.layers.Dense(1)\n",
        ")\n",
        "\n",
        "# Compiling our model\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.mae,\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=0.1),\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "# Now fit the model\n",
        "model.fit(tf.expand_dims(x,axis=1),y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upH-_gT81I1V",
        "outputId": "f5757f35-4bfb-4f7e-8b0e-0f92956ad97d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 464ms/step - loss: 10.5736 - mae: 10.5736\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.1236 - mae: 10.1236\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6736 - mae: 9.6736\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2236 - mae: 9.2236\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7736 - mae: 8.7736\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3236 - mae: 8.3236\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8736 - mae: 7.8736\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4236 - mae: 7.4236\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9736 - mae: 6.9736\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8250 - mae: 6.8250\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7706 - mae: 6.7706\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9023 - mae: 6.9023\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9798 - mae: 6.9798\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0115 - mae: 7.0115\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0041 - mae: 7.0041\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9629 - mae: 6.9629\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7967 - mae: 6.7967\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6786 - mae: 6.6786\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5410 - mae: 6.5410\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3862 - mae: 6.3862\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2161 - mae: 6.2161\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0324 - mae: 6.0324\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9317 - mae: 5.9317\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8711 - mae: 5.8711\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8089 - mae: 5.8089\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7619 - mae: 5.7619\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7609 - mae: 5.7609\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7017 - mae: 5.7017\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 5.5917 - mae: 5.5917\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4656 - mae: 5.4656\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3926 - mae: 5.3926\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3197 - mae: 5.3197\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2467 - mae: 5.2467\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1738 - mae: 5.1738\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1009 - mae: 5.1009\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0279 - mae: 5.0279\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9770 - mae: 4.9770\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.9214 - mae: 4.9214\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8387 - mae: 4.8387\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7472 - mae: 4.7472\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.6789 - mae: 4.6789\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.6100 - mae: 4.6100\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5405 - mae: 4.5405\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4706 - mae: 4.4706\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4002 - mae: 4.4002\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3295 - mae: 4.3295\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2584 - mae: 4.2584\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1869 - mae: 4.1869\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1152 - mae: 4.1152\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0432 - mae: 4.0432\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9710 - mae: 3.9710\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8986 - mae: 3.8986\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8259 - mae: 3.8259\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7531 - mae: 3.7531\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6802 - mae: 3.6802\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6071 - mae: 3.6071\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5339 - mae: 3.5339\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4605 - mae: 3.4605\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3871 - mae: 3.3871\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3135 - mae: 3.3135\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2399 - mae: 3.2399\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1662 - mae: 3.1662\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0924 - mae: 3.0924\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0220 - mae: 3.0220\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9468 - mae: 2.9468\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8747 - mae: 2.8747\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8024 - mae: 2.8024\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7299 - mae: 2.7299\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6571 - mae: 2.6571\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5841 - mae: 2.5841\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5110 - mae: 2.5110\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4377 - mae: 2.4377\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3642 - mae: 2.3642\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2906 - mae: 2.2906\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2169 - mae: 2.2169\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1431 - mae: 2.1431\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0692 - mae: 2.0692\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0054 - mae: 2.0054\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9234 - mae: 1.9234\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8512 - mae: 1.8512\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7788 - mae: 1.7788\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7061 - mae: 1.7061\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6331 - mae: 1.6331\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5600 - mae: 1.5600\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4867 - mae: 1.4867\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4132 - mae: 1.4132\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3395 - mae: 1.3395\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2657 - mae: 1.2657\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1918 - mae: 1.1918\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1178 - mae: 1.1178\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0437 - mae: 1.0437\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9695 - mae: 0.9695\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8952 - mae: 0.8952\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8208 - mae: 0.8208\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7464 - mae: 0.7464\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6828 - mae: 0.6828\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5997 - mae: 0.5997\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5291 - mae: 0.5291\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4521 - mae: 0.4521\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabf85b79d0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remindr of what x and y was\n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s971TM0N2dkC",
        "outputId": "da0ff7a7-e732-4442-f1a2-00d14d651eac"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVXOeebT25kR",
        "outputId": "d4147060-1c90-4685-d733-af02887d9dbc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 162ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.497076]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model again with another change\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling our model\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.mae,\n",
        "    optimizer = tf.keras.optimizers.SGD(),\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "# Now fit the model\n",
        "model.fit(tf.expand_dims(x,axis=1),y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEjx-S1F297Y",
        "outputId": "8b1fd199-de92-46f7-b647-d8ec0823e44d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 13.5267 - mae: 13.5267\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.9594 - mae: 12.9594\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3983 - mae: 12.3983\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.8281 - mae: 11.8281\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2463 - mae: 11.2463\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.6465 - mae: 10.6465\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3938 - mae: 9.3938\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7211 - mae: 8.7211\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0110 - mae: 8.0110\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.2573 - mae: 7.2573\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4531 - mae: 6.4531\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5874 - mae: 5.5874\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6583 - mae: 4.6583\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0382 - mae: 4.0382\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9405 - mae: 3.9405\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9362 - mae: 3.9362\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9147 - mae: 3.9147\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9427 - mae: 3.9427\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8977 - mae: 3.8977\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9583 - mae: 3.9583\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8904 - mae: 3.8904\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9447 - mae: 3.9447\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8969 - mae: 3.8969\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9188 - mae: 3.9188\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9035 - mae: 3.9035\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8928 - mae: 3.8928\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9169 - mae: 3.9169\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8749 - mae: 3.8749\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9260 - mae: 3.9260\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8586 - mae: 3.8586\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9219 - mae: 3.9219\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8653 - mae: 3.8653\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8958 - mae: 3.8958\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8721 - mae: 3.8721\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8744 - mae: 3.8744\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8879 - mae: 3.8879\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8513 - mae: 3.8513\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8949 - mae: 3.8949\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8279 - mae: 3.8279\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8978 - mae: 3.8978\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8348 - mae: 3.8348\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8714 - mae: 3.8714\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8443 - mae: 3.8443\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8531 - mae: 3.8531\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8579 - mae: 3.8579\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8263 - mae: 3.8263\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8651 - mae: 3.8651\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7994 - mae: 3.7994\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8724 - mae: 3.8724\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8054 - mae: 3.8054\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8462 - mae: 3.8462\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8216 - mae: 3.8216\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8271 - mae: 3.8271\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8289 - mae: 3.8289\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8000 - mae: 3.8000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8363 - mae: 3.8363\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7728 - mae: 3.7728\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8438 - mae: 3.8438\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7772 - mae: 3.7772\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8254 - mae: 3.8254\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7935 - mae: 3.7935\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7998 - mae: 3.7998\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8010 - mae: 3.8010\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7724 - mae: 3.7724\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8086 - mae: 3.8086\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7449 - mae: 3.7449\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8163 - mae: 3.8163\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7538 - mae: 3.7538\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7987 - mae: 3.7987\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7664 - mae: 3.7664\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7711 - mae: 3.7711\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7741 - mae: 3.7741\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7435 - mae: 3.7435\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7819 - mae: 3.7819\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7162 - mae: 3.7162\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7899 - mae: 3.7899\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7327 - mae: 3.7327\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7690 - mae: 3.7690\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7405 - mae: 3.7405\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7411 - mae: 3.7411\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7484 - mae: 3.7484\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7132 - mae: 3.7132\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7564 - mae: 3.7564\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6909 - mae: 3.6909\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7650 - mae: 3.7650\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7077 - mae: 3.7077\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7380 - mae: 3.7380\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7156 - mae: 3.7156\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7098 - mae: 3.7098\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7236 - mae: 3.7236\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6815 - mae: 3.6815\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7318 - mae: 3.7318\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6710 - mae: 3.6710\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7340 - mae: 3.7340\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6835 - mae: 3.6835\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7056 - mae: 3.7056\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6916 - mae: 3.6916\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6771 - mae: 3.6771\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6999 - mae: 3.6999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabf8327190>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qCUASwR4X9V",
        "outputId": "9fc30df9-4101-4660-b2e6-55c5cc940383"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScCJclKjAYoL",
        "outputId": "136262ee-fd40-4f26-a750-75f49c31dcbc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.824465]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model again with another change\n",
        "model = tf.keras.Sequential(\n",
        "    tf.keras.layers.Dense(1)\n",
        ")\n",
        "\n",
        "# Compiling our model\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.mae,\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=0.1),\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "# Now fit the model\n",
        "model.fit(tf.expand_dims(x,axis=1),y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFeDUfGPAdL1",
        "outputId": "0965d08a-c9a0-40ca-dcbf-a048ac500626"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 425ms/step - loss: 19.2532 - mae: 19.2532\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 18.6532 - mae: 18.6532\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 18.0532 - mae: 18.0532\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 17.4532 - mae: 17.4532\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 16.8532 - mae: 16.8532\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.2532 - mae: 16.2532\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 15.6532 - mae: 15.6532\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 15.0532 - mae: 15.0532\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.4532 - mae: 14.4532\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.8532 - mae: 13.8532\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.3355 - mae: 13.3355\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.8924 - mae: 12.8924\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.4550 - mae: 12.4550\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.0222 - mae: 12.0222\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.5933 - mae: 11.5933\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.1677 - mae: 11.1677\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.7447 - mae: 10.7447\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.3240 - mae: 10.3240\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.9051 - mae: 9.9051\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4878 - mae: 9.4878\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0716 - mae: 9.0716\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6566 - mae: 8.6566\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.2423 - mae: 8.2423\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.8286 - mae: 7.8286\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4154 - mae: 7.4154\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0026 - mae: 7.0026\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.5900 - mae: 6.5900\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.1775 - mae: 6.1775\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.7651 - mae: 5.7651\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.3526 - mae: 5.3526\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.1739 - mae: 5.1739\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1557 - mae: 5.1557\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 5.2849 - mae: 5.2849\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3795 - mae: 5.3795\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4425 - mae: 5.4425\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5233 - mae: 5.5233\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5666 - mae: 5.5666\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5466 - mae: 5.5466\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4707 - mae: 5.4707\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.3451 - mae: 5.3451\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1754 - mae: 5.1754\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9956 - mae: 4.9956\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8432 - mae: 4.8432\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6832 - mae: 4.6832\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5162 - mae: 4.5162\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3428 - mae: 4.3428\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2294 - mae: 4.2294\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1777 - mae: 4.1777\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.1239 - mae: 4.1239\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.1771 - mae: 4.1771\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.1920 - mae: 4.1920\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.1612 - mae: 4.1612\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0893 - mae: 4.0893\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9802 - mae: 3.9802\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8378 - mae: 3.8378\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.6721 - mae: 3.6721\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6005 - mae: 3.6005\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5290 - mae: 3.5290\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4577 - mae: 3.4577\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4152 - mae: 3.4152\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3854 - mae: 3.3854\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3344 - mae: 3.3344\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2643 - mae: 3.2643\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1768 - mae: 3.1768\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0735 - mae: 3.0735\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9966 - mae: 2.9966\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9341 - mae: 2.9341\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.8707 - mae: 2.8707\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8064 - mae: 2.8064\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7433 - mae: 2.7433\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6770 - mae: 2.6770\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.6032 - mae: 2.6032\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5328 - mae: 2.5328\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4623 - mae: 2.4623\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3916 - mae: 2.3916\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3209 - mae: 2.3209\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2500 - mae: 2.2500\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2065 - mae: 2.2065\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1431 - mae: 2.1431\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0599 - mae: 2.0599\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9776 - mae: 1.9776\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9115 - mae: 1.9115\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8447 - mae: 1.8447\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7774 - mae: 1.7774\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7095 - mae: 1.7095\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6479 - mae: 1.6479\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.5702 - mae: 1.5702\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4991 - mae: 1.4991\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4279 - mae: 1.4279\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3566 - mae: 1.3566\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2851 - mae: 1.2851\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2260 - mae: 1.2260\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1545 - mae: 1.1545\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0765 - mae: 1.0765\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0084 - mae: 1.0084\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9397 - mae: 0.9397\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8707 - mae: 0.8707\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8167 - mae: 0.8167\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7292 - mae: 0.7292\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6572 - mae: 0.6572\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabf74ed210>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WpC3HUoB4rr",
        "outputId": "8ffc2e83-6a57-4e4d-9551-54db9fd3f64b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.497189]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Model\n",
        "\n",
        "In practice  a typical work flow you go through is\n",
        "\n",
        "Build amodel -> fit it -> evaluate it -> tweal a model -> fit it -> evaluate it"
      ],
      "metadata": {
        "id": "1cAG8YiACAgb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluating there are 3 words you should memorize:\n",
        "   \" Visualize,visualize,visualize\"\n",
        "it's good idea to visualize:\n",
        "   * The data - what data we are working with? What does it look like?\n",
        "   * The model itself - what does our model looks like ?\n",
        "   * The Training of a model - how does a model perfoms while it learns\n",
        "   * The prediction of a model - how do the prediction of a model line up against the ground truth (The orignal labels)?"
      ],
      "metadata": {
        "id": "S-YqIxNgCzAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a biger data set\n",
        "x = tf.range(-100,100,4)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cfQfGLeELNj",
        "outputId": "4095499d-cff6-4fcb-d589-cb11611b2772"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=x+10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QfbUghxEVUQ",
        "outputId": "ddb0702b-3cb2-41dd-8734-220153b8930c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data \n",
        "plt.scatter(x,y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "C3NEQPjLEa3A",
        "outputId": "1b155209-5e64-4dcd-deed-c312c5286cbe"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets ....\n",
        "\n",
        "* Training set - the model learns from this data and it is typicaly 70-80 percent of data.\n",
        "* Validation set - the model gets tunned on this data which is typically 10 to 15 % of total data\n",
        "* Test set - The model is evaluated usingf this data"
      ],
      "metadata": {
        "id": "EarLzXIvEn1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the leanght of how many samples we have\n",
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co6JE1THFvv0",
        "outputId": "f03f4352-4a27-45b1-8c69-fbc1c016f4f7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "x_train = x[:40] \n",
        "y_train = y[:40]\n",
        "x_test = x[40:]\n",
        "y_test = y[40:]\n",
        "len(x_train),len(x_test),len(y_train),len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKECIR_wF3Tf",
        "outputId": "70e150a9-81a3-48ab-9897-b4c837f309d0"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing our data\n",
        "Now lets visualize the sets"
      ],
      "metadata": {
        "id": "SSSGRIieF_NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "# Plot training data in blue\n",
        "plt.scatter(x_train,y_train,c=\"b\",label=\"Training Data\")\n",
        "plt.scatter(x_test,y_test,c=\"g\",label=\"Testing Data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "G31eJkLrGuzY",
        "outputId": "3c7e5973-f0c6-4a62-b7dc-5e38722c9faa"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets have a look at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.mae,\n",
        "    optimizer = tf.keras.optimizers.SGD(),\n",
        "    metrics = [\"mae\"]\n",
        ")\n",
        "# 3. Fit the model\n",
        "# model.fit(x_train,y_train,epochs=100)"
      ],
      "metadata": {
        "id": "XM1qBt1tHOF4"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the model"
      ],
      "metadata": {
        "id": "b55T_tjKJjRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a model that builds automatically by defining the input shape\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1,input_shape=[1])\n",
        "])\n",
        "# 2 compile a model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "awFT2yJnJqBf"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPaBPTrKKp7B",
        "outputId": "d0562e7b-bf4c-4743-b64e-a5a9b9976b65"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_46 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Total parameters our model is going to learn\n",
        "* Trainable Pramater 2 means all the parameters in the model are trainable\n",
        "* Non-Trainable prams these parameters are not trainable "
      ],
      "metadata": {
        "id": "iu3kij3aKwfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets fit our model to the trianing data\n",
        "model.fit(x,y,epochs=100,verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vp_QYYfLIUV",
        "outputId": "0cb77627-db0f-40b6-ef53-411e3dd9c7d6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabf51c66d0>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "187RzX5gMs-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}